{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtUBrTJR4xN1Nk+91Ar3BT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yezz1n/ESAA_OCT/blob/main/ESAA_fourth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#사이킷런\n",
        "\n",
        ":파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리\n",
        "\n",
        "가장 쉽고 효율적인 개발 라이브러리 제공\n",
        "\n",
        "* 파이썬 기반의 다른 머신러닝 패키지도 사이킷런 스타일의 API를 지향-> 가장 파이썬 스러운 API 제공\n",
        "\n",
        "* 머신러닝을 위한 매우 다양한 알고리즘과 개발을 위한 편안한 프레임워크와 API 제공\n",
        "\n",
        "* 오랜 기간 실전 환경에서 검증됐으며, 매우 많은 환경에서 사용되는 성숙한 라이브러리"
      ],
      "metadata": {
        "id": "h8sGVlxzbufS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "uKD_91C7a9Ha",
        "outputId": "745d1c07-edaa-49be-9aa7-275552f236b6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-e5cc35c9a6f4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install scikit-learn\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#사이킷런 설치\n",
        "#pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##붓꽃 품종 예측하기\n",
        "\n",
        ":붓꽃 데이터 세트는 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처 기반으로 꽃의 품조 예측\n",
        "\n",
        "\n",
        "###분류\n",
        ": 대표적인 지도학습 방법의 하나\n",
        "\n",
        "###지도학습\n",
        ":학습을 위한 다양한 피처와 분류 결정값인 레이블 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측한다.\n",
        "\n",
        "-> 지도학습은 명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측 하는 방식\n",
        "\n",
        "* 학습을 위해 주어진 데이터 세트: 학습 데이터 세트\n",
        "* 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트: 테스트 데이터 세트\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* sklearn\n",
        "  * sklearn.datasets: 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는 모듈의 모임\n",
        "\n",
        "  * sklearn.tree: 트리 기반 ML알고리즘을 구현한 클래스의 모임\n",
        "  \n",
        "  * sklearn.model_selection: 학습 데이터와 검증 데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임\n",
        "      * 하이퍼 파라미터: 머신러닝 알고리즘 별로 최적의 학습을 위해 직접 입력하는 파라미터들의 통칭/이를 통해 머신러닝 알고리즘의 성능을 튜닝할 수 있다."
      ],
      "metadata": {
        "id": "uGaC9ghBc61m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ao0LU5U8c2Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "JBbIJrAUeiJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris=load_iris()\n",
        "\n",
        "#iris.data는  iris 데아터 세트에서 피처만으로 된 데이터를 numpy로 가지고 있다\n",
        "\n",
        "iris_data=iris.data\n",
        "\n",
        "#iris.target은 붓꽃 데이터 세트에서 레이블(결정 값)데이터를 numpy로 가지고 있다.\n",
        "\n",
        "iris_label=iris.target\n",
        "\n",
        "print('iris target 값:',iris_label)\n",
        "print('iris target 명:',iris.target_names)\n",
        "\n",
        "#붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 전환\n",
        "\n",
        "iris_df=pd.DataFrame(data=iris_data,columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "5XKovihPe1Y8",
        "outputId": "33fe3811-2974-4cd6-a57a-e7cad0416e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris target 값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "iris target 명: ['setosa' 'versicolor' 'virginica']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70e60779-76d4-46c0-bcfa-fa39caa6ce82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70e60779-76d4-46c0-bcfa-fa39caa6ce82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70e60779-76d4-46c0-bcfa-fa39caa6ce82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70e60779-76d4-46c0-bcfa-fa39caa6ce82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블(label)은 0,1,2 3가지 값으로 돼 있으며 0이 setosa 품종, 1이 versicolor 품종, 2가 virginica 품종을 의미\n",
        "\n",
        "학습용 데이터와 테스트용 데이터를 분리\n",
        "\n",
        "<font color='red'> 반드시 분리 필요\n",
        "\n",
        ":뛰어난 성능 평가 위해서는 테스트 데이터 세트가 필요\n",
        "\n",
        "->사이킷런은 train_test_split() API 제공\n",
        "\n",
        "*  train_test_split() 을 이용하면 학습 데이터와 테스트 데이터를 test_size 파라미터 입력 값을 비율로 쉽게 분할\n",
        "\n",
        "ex) test_size=0.2로 입력 파리미터 설정 시 전체 데이터 중 테스트 데이터가 20% 학습 데이터가 80%로 데이터를 분할\n",
        "\n",
        "  * train_test_split() 호출 시 무작위로 데이터를 분리하므로 random_state를 지정해야 일정한 숫자값으로 분리 가능==seed같은 기능\n"
      ],
      "metadata": {
        "id": "iUVIXBdif9gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(iris_data,iris_label,test_size=0.2,random_state=11)\n",
        "\n",
        "#iris_data:피쳐 데이터 세트/iris_label:레이블 데이터 세트/test_size:전체 데이터 세트 중 테스트 데이터 세트의 비율\n",
        "#random_state:호출 시 마다 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값"
      ],
      "metadata": {
        "id": "X3VgHHLXg2sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 사이킷런의 의사결정 트리 클래스:DecisionTreeClassifier\n",
        "   * fit() 메소드에 학습용 피처 뎅터 속성과 결정값 데이터 세트를 입력해 호출하면 학습 수행\n"
      ],
      "metadata": {
        "id": "tQcJ2vj5H7i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf=DecisionTreeClassifier(random_state=11)\n",
        "dt_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzcPArp6IK4C",
        "outputId": "4a87fc90-c159-44d1-d7be-cb2f74254753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=11)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   * DecisionTreeClassifier를 이용해 예측 수행 가능\n",
        "* 예측 시 반드시 학습 데이터가 아닌 다른 데이터를 이용해야함, 일반적으로 testdata 이용\n",
        " * predict()"
      ],
      "metadata": {
        "id": "xx85DhNZIwUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred=dt_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "CAd_emVtIyUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 정확도 측정\n",
        ":예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표\n",
        " * accuacy_count()"
      ],
      "metadata": {
        "id": "CFMvXOCxI3Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#붓꽃 데이터의 붓꽃 품종과 실제 테스트 데이터 세트의 붓꽃 품종이 얼마나 일치하는지 확인\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN4hhmP3JH8s",
        "outputId": "f2d36dba-95ca-489b-d19e-755371243d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'> 예측 프로세스 정리\n",
        "\n",
        "1. 데이터 세트 분리; 데이터를 학습 데이터와 테스트 데이터로 분리\n",
        "\n",
        "2. 모델 학습: 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습\n",
        "\n",
        "3. 예측 수행: 학습된 ML 모델을 이용해 테스트 데이터의 분류를 예측(여기선 붓꽃 종류)\n",
        "\n",
        "4. 평가: 이렇게 예측된 결과값과 테스트 데이터의 실제 결과값을 비교해 ML 모델 성능을 평가\n",
        "\n",
        "\n",
        "###사이킷런의 기반 프레임워크 익히기\n",
        "\n",
        "###Estimator 이해 및 fit(),predict() 메서드\n",
        "\n",
        "* fit(): ML 모델 학습 위해서\n",
        "\n",
        "* predict(): 학습된 모델 예측\n",
        "\n",
        "->지도학습의 주요 두 축인 분류와 회귀의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 두가지만을 이요해서 간단하게 학습과 예측 결과 반환\n",
        "\n",
        "* Classifier :분류 알고리즘을 구현한 클래스\n",
        "\n",
        "* Regressor:회귀 알고리즘을 구현한 클래스\n",
        "\n",
        "  ->둘을 합쳐 \"Estimator\" 클래스라고 부른다\n",
        "(fit() predict() 내부에서 구현하고 있다)\n",
        "\n",
        "  *  cross_val_score() 같은 evaluation 함수, GridSearchCV와 같은 하이퍼 파라미터 튜닝을 지원하는 클래스의 경우 이 Estimator을 인자로 받음\n",
        "\n",
        " * 인자로 받은 Estimator에 대해서 cross_val_score(),GridSearchCV.fit() 함수 내에서 이 Estimator의 fit() 과 predict()를 호출해서 평가를 하거나 하이퍼 파라미터 튜닝을 수행\n",
        "\n",
        " * 비지도학습인 차원 축소, 클러스터링, 피처 추출 등을 구현한 클래스 역시 대부분 fit()과 transform()을 적용\n",
        "  * fit(): 지도학습과 의미 다름. 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞춤\n",
        "  * transform(): 사전 구조 맞춘 이후 입력 데이터의 차원 변호나, 클러스터링, 피처 추출 등의 실제 작업은 transform()으로 수행\n",
        "  * fit_transform(): 둘을 하나로 결합, 별도로 호출할 필요를 줄여주지만, 사용에 약간 주의 필요\n",
        "\n",
        "###사이킷런의 주요 모듈\n",
        "\n",
        "* 예제 데이터\n",
        " * sklearn.datasets: 사이킷런에 내장되어 있는 예제로 제공하는 데이터 세트\n",
        "* 피처 처리\n",
        " * sklearn.preprocessing: 데이터 전처리에 필요한 다양한 가공 기능 제공(문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링)\n",
        " * sklearn.feature_selection: 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능을 제공\n",
        " * skelearn.feature_extraction\n",
        "  * 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용됨\n",
        "\n",
        "    ex) 예를 들어 텍스트 데이터에서 Count Vectorizer나 Tf-ldf Vectorizer 등을 생성하는 기능 제공\n",
        "  * 텍스트 데이터의 피처 추출은 sklearn.feature_extraction, text 모듈에 이미지 데이터의 피처 추출은 sklearn.feature_extraction.image 모듈에 지원 API가 있음\n",
        "\n",
        "* 피처 처리&차원 축소\n",
        " * sklearn.decomposition:차원 축소와 관련한 알고리즘을 지원하는 모듈. PCA,NMF, Truncated SVD등을 통해 차원 축소 기능을 수행할 수 있음\n",
        "\n",
        "* 데이터 분리, 검증& 파라미터 튜닝\n",
        " * sklearn.model_selection: 교차 검증을 위한 학습용/ 테스트용 분리, 그리드 서치로 최적 파라미터 추출 등의 API 제공\n",
        "\n",
        "* 평가 \n",
        " * sklearn.metrics: 분류, 회귀, 클러스터링, 페어와이즈에 대한 다양한 성능 측정 방법 제공\n",
        "  * accuracy, precision, recall, ROC_AUC, RMSE 등 제공\n",
        "\n",
        "* 알고리즘\n",
        " * sklearn.ensemble :앙상블 알고리즘 제공 \n",
        "    * 랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 등 제공\n",
        " * sklearn,linear_model: 주로 선형 회귀, 릿지, 라쏘 및 로지스틱 회귀 등 회귀 관련 알고리즘을 지원, 또한, SGD 관련 알고리즘도 제공\n",
        " * sklearn.naive_bayes: 나이브 베이즈 알고리즘 제공, 가우시안 NB, 다항 분포 NB\n",
        " * sklearn.neighbors :최근접 이웃 알고리즘 제공, K-NN\n",
        " * sklearn.svm: 서포트 벡터 머신 알고리즘 제공\n",
        " * sklearn.cluster : 비지도 클러스터링 알고리즘 제공(K-평균, 계층형, \n",
        " DBSCAN)\n",
        "* 유틸리티\n",
        " * sklearn.pipeline: 피처 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어 실행할 수 있는 유틸리티 제공\n",
        "\n",
        "\n",
        "\n",
        "일반적으로 머신러닝 모델을 구축하는 주요 프로세스: 피처의 가공, 변경, 추출을 수행하는 피처 처리, ML 알고리즘 학습/예측 수행, 모델 평가의 단계 반복적으로 수행\n",
        "\n",
        "####내정된 예제 데이터 세트\n",
        ": 사이킷런 내부에 데이터 세트 \n",
        " \n",
        "* datasets.load_boston():회귀 용도, 미국 보스톤의 집 피처들과 가격에 대한 데이터 세트\n",
        "\n",
        "* datasets.load_breast_cancer(): 분류 용도, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트\n",
        "\n",
        "* datasets.load_diabetes(): 회귀 용도, 당뇨 데이터 세트\n",
        "\n",
        "* datasets.load_digits(): 분류 용도 0-9까지 숫자의 이미지 픽셀 데이터 세트\n",
        "\n",
        "* datasets.load_iris(): 분류 용도 붓꽃에 대한 피처를 가진 데이터 세트\n",
        "\n",
        "\n",
        "* fetch 계열의 명령은 인터넷에서 내려받아서 사용 데이터\n",
        "\n",
        "  * fetch_covtype(): 회귀 분석용 토지 조사 자료\n",
        "  * fetch_20newsgroups(): 뉴스 그룹 텍스트 자료\n",
        "  * fetch_olivetti_faces(): 얼굴 이미지 자료\n",
        "  * fetch_lfw_people():  얼굴 이미지 자료\n",
        "  * fetch_lfw_party(): 얼굴 이미지 자료\n",
        "  * fetch_rcv1(): 로이터 뉴스 말뭉치\n",
        "  * fetch_mldata():ML 웹사이트에서 다운로드\n",
        "\n",
        "* 분류와 클러스터링을 위한 표본 데이터 생성기 \n",
        " * datasets.make_classifications(): 분류를 위한 데이터 세트를 만듦. 특히, 높은 상관도, 불필요한 속성 등의 노이즈 효과를 위한 데이터를 무작위로 생성해줌\n",
        " * datasets.make_blobs():클러스터링을 위한 데이터 세트를 무작위로 생성해줌. 군집 지정 개수에 따라 여러가지 클러스터링을 위한 데이터 세트를 쉽게 만들어줌\n",
        "\n",
        " 사이킷런 내장된 이 데이터 세트는 일반적으로 딕셔너리 형태로 돼있음\n",
        "\n",
        "\n",
        " 키는 보통 data, target, target_name, feature_names,DESCR로 구성돼 있음\n",
        "\n",
        " * data: 피처의 데이터 세트\n",
        " * target: 분류 시 레이블 값, 회귀일 때는 숫자 결과값 데이터 세트\n",
        " * target_names: 개별 레이블의 이름\n",
        " * feature_names:피처의 이름\n",
        " * DESCR:데이터 세트에 대한 설명과 각 피처의 설명\n",
        "  * data,target은 넘파이 배열 타입\n",
        "  * target_names,feature_names는 넘파이 배열 또는 파이썬 리스트\n",
        "  * DESCR 스트링 타입\n",
        "  --> 피처의 데이터 값을 반환받기 위해서는 내장 데이터 세트 API를 호출한 뒤에 그 key 값을 지정하면 된다\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "nDjskNfHJHvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data=load_iris()\n",
        "print(type(iris_data))"
      ],
      "metadata": {
        "id": "725NmXfpdOG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8fcab9-b527-4b64-9861-ab8b720b960f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ": 이 때 Bunch 클래스는 파이썬 딕셔너리 자료형과 유사\n",
        "데이터 세트에 내장돼 있는 대부분의 데이터 세트는 이와 같이 딕셔너리 형태의 값을 반환\n"
      ],
      "metadata": {
        "id": "MRcNyZSEWYh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#딕셔너리 형태의 데이터 세트의 key 값 확인하기\n",
        "\n",
        "keys=iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:',keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzzaww9EWYIl",
        "outputId": "09f231c0-2602-4743-b6dc-94190392d5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ":데이터 키는 피처들의 데이터 값을 가리킴\n",
        "\n",
        "데이터 세트가 딕셔너리 형태이기 때문에 피처 데이터 값을 추출하기 위해서는 데이터 세트.data를 이용하면 됨\n",
        "\n",
        "target,feature_names,DESCR key가 가리키는 데이터 값의 추출도 동일하게 수행하면 됨\n",
        "\n"
      ],
      "metadata": {
        "id": "PrsR2qQDWytC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load_iris()가 반환하는 객체의 키인 feature_names,target_name,data,target이 가리키는 값?\n",
        "print('\\n feature_names의 type:',type(iris_data.feature_names))\n",
        "print(' feature_names의 shape:',len(iris_data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "\n",
        "print('\\n target_names의 type:',type(iris_data.target_names))\n",
        "print('target_names의 shape:',len(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('\\n data의 type:',type(iris_data.target))\n",
        "print('target의 shape:',iris_data.target)\n",
        "print(iris_data.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQWBbfsvXChG",
        "outputId": "dc5d0638-6ec0-4023-e227-4f921cca3121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " feature_names의 type: <class 'list'>\n",
            " feature_names의 shape: 4\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "\n",
            " target_names의 type: <class 'numpy.ndarray'>\n",
            "target_names의 shape: 3\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "\n",
            " data의 type: <class 'numpy.ndarray'>\n",
            "target의 shape: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Selection 모듈\n",
        "\n",
        "사이킷런의 model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나 교차 검증 분할 및 평가, 그리고 estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스를 제공\n",
        "\n",
        "#### train_test_split(): 학습 데이터/ 테스트 데이터 세트 분리\n",
        "학습 데이터 세트 기반으로 예측하였기 때문에 정확도 위해 원본 데이터에서 학습 및 테스트 데이터 세트를 분리 필요 O\n",
        "* train_test_split():첫번째 파라미터로 피처 데이터 세트, 두번째 파라미터로 레이블 데이터 세트, 선택적으로 다음 파라미터 입력받기도 함\n",
        " * test_size: 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정. 디폴트는 0.25\n",
        " * train_size: 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정. test_size parameter를 통상적으로 사용하기 때문에 train_size는 잘 사용하지 x\n",
        " * shuffle: 데이트를 분리하기 전에 데이터를 미리 섞을지를 결정. 디폴트는 True, 데이터를 분산시켜서 좀 더 효율적인 학습 및 테스트 데이터 세트를 만드는 데 사용\n",
        " * random_state: 호출할 때마다 동일한 학습/ 테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값. train_test_split()은 호출 시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 학습.테스트 용 데이터를 생성"
      ],
      "metadata": {
        "id": "1n4NgSqmYRXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris=load_iris()\n",
        "dt_clf=DecisionTreeClassifier()\n",
        "train_data=iris.data\n",
        "train_label=iris.target\n",
        "\n",
        "dt_clf.fit(train_data,train_label)\n",
        "\n",
        "#학습 데이터 세트로 예측 수행\n",
        "pred=dt_clf.predict(train_data)\n",
        "print('예측 정확도:',accuracy_score(train_label,pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb2zQyKFYoyQ",
        "outputId": "4e103a49-bd3d-4701-8879-0817d3f4a699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#붓꽃 데이터 세트를 train_test_split()을 이용해 테스트 데이터 세트를 전체의 30%, 학습 데이터 세트를 70%로 분리. \n",
        "dt_clf=DecisionTreeClassifier()\n",
        "iris_data=load_iris()\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.3,random_state=121)\n",
        "\n",
        "#학습 데이터 기반 DecisionTreeClassifier을 학습하고 이 모델을 이용해 예측 정확도를 측정\n",
        "dt_clf.fit(X_train,y_train)\n",
        "pred=dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3MeBh-EbfgS",
        "outputId": "d10a2171-353c-4336-b156-bf6b256f4ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.9556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습을 위한 데이터의 양을 일정 수준 이상으로 보장하는 것도 중요하지만, 학습된 모델에 대해 다양한 데이터를 기반으로 예측 성능을 평가해보는 것도 중요\n",
        "\n",
        "###교차 검증\n",
        "* 과적합: 모델이 학습 데이터에만 과도하게 최적화 되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어짐.\n",
        "\n",
        "학습용 데이터와 테스트 데이터를 이용해 평가하다 보면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향되게 모델 유도하는 경향이 생겨 다르 테스트 데이터가 들어오면 성능이 저하될 수 있다.\n",
        "\n",
        "* 교차 검증: 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행한 후에 테스트 데이터 세트에 대해 평가\n",
        "\n",
        "ML은 데이터에 기반. 데이터는 이상치, 분포도, 다양한 속성값, 피처 중요도 등 여러가지 ML에 미치는 요소를 가지고 있다.\n",
        "\n",
        "데이터 편중을 막기 위해 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행. 각 세트에서 수행한 평가 결과에 따라 하이퍼 파라미터 튜닝 드으이 모델 최적화를 더 손쉽게 할 수 있다.\n",
        "\n",
        "대부분의 ML 모델의 성능 평가는 교차 검증 기반을 1차 평가를 한 뒤에 최종적으로 테스트 epdlxj tpxm 적용해 평가하는 프로세스.\n",
        "\n",
        "ML 모델의 성능 평가 대부분은 교차 검증 기반으로 1차 평가를 한 뒤에 최종적으로 테스트 데이터 세트에 적용해 평가하는 프로세스\n",
        "ML에 사용되는 데이터 세트를 세분화해서 학습, 검증, 테스트 데이터 세트로 나눌 수 있다.\n",
        "\n",
        "테스트 데이터 세트 외에 별도의 검증 데이터 세트를 둬서 최종 평가 이전에 학습된 모델을 다양하게 평가하는데 사용\n",
        "\n",
        "#### K 폴드 교차 검증\n",
        ":가장 보편적. K개의 데이터 폴드 세트를 만들어서 K번칸큼 각 폴트 세트에 학습과 검증 평가 방법을 반복적으로 수행하는 방법\n",
        "\n",
        "ex) K=5\n",
        "5개의 폴드된 데이터 세트를 학습과 검증을 위한 데이터 세트로 변경하면서 5번 평가를 수행한 뒤, 이 5개의 평가를 평균한 결과를 가지고 예측 성능을 평가\n",
        "-데이터 세트를 5등분\n",
        "-첫번째 반복에서 처음부터 4개 등분을 학습 데이터 세트, 마지막 5번째 등분 하나를 검증 데이터 세트로 설정하고 학습 데이터 세트에서 학습 수행, 검증 데이터 세트에서 평가를 수행\n",
        "-첫번째 평가를 수행하고 나면 이제 두번째 반복에서 다시 비슷한 학습과 평가 작업을 수행\n",
        "->이번에는 학습 데이터와 검증 데이터를 변경(처음부터 3개 등분까지, 그리고 마지막 5번째 등분을 학습 데이터 세트로 4번째 등분 하나를 검증 데이터 세트로 설정\n",
        "-반복\n",
        "\n",
        "\n",
        ":KFold StratifiedKFold 클래스\n"
      ],
      "metadata": {
        "id": "VuLVyUaFbfQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "iris=load_iris()\n",
        "features=iris.data\n",
        "label=iris.target\n",
        "dt_clf=DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "#5개의 폴드 세트로 분리하는 Kfold 객체와 폴드 세트별 정학도를 담을 리스트 객체 생성\n",
        "kfold=KFold(n_splits=5)\n",
        "cv_accuracy=[]\n",
        "print('붓꽃 데이터 세트 크기:',features.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BpB0He_kmUW",
        "outputId": "b9be3576-d9dd-4718-b0fd-2061de768506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter=0\n",
        "#KFold 객체의 split()을 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index,test_index in kfold.split(features):\n",
        "  #kfold.split.()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train,X_test=features[train_index],features[test_index]\n",
        "  y_train,y_test=label[train_index],label[test_index]\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train,y_train)\n",
        "  pred=dt_clf.predict(X_test)\n",
        "  n_iter+=1\n",
        "  #반복 시마다 정확도 측정\n",
        "  accuracy=np.round(accuracy_score(y_test,pred),4)\n",
        "  train_size=X_train.shape[0]\n",
        "  test_size=X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter,accuracy,train_size,test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "#개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도:',np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Y3tNa_mNbA",
        "outputId": "af399170-5298-4bf2-cf23-a90890b1c081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도: 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stratified K 폴드\n",
        ":불균형한 분포도를 가진 레이블 데이터 집합을 위한 K폴드 방식<왜곡된 데이터>\n",
        "\n",
        "->불균형한 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배 \n",
        "ex)대출 사기\n",
        "\n",
        "* 일반적으로 분류에서 교차검증은 Stratified K 폴드로 분할돼야 함\n",
        " *회귀에서는 지원되지 않음:회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에 결정값 별로 분포를 정하는 의미가 없다"
      ],
      "metadata": {
        "id": "oJTqolN4klrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setosa, versicolor, virginica 품종 모두가 50개\n",
        "#이슈가 발생하는 현상을 도출하기 위해 3개의 폴드 세트를 Kfold로 생성하고, 각 교차 검증 시마다 생성되는 학습/ 검증 레이블 데이터 값의 데이터 값 분포도 확인\n",
        "\n",
        "kfold=KFold(n_splits=3)\n",
        "n_iter=0\n",
        "for train_index,test_index in kfold.split(iris_df):\n",
        "  n_iter+=1\n",
        "  label_train=iris_df['label'].iloc[train_index]\n",
        "  label_test=iris_df['label'].iloc[test_index]\n",
        "  print('## 교차검증:{0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n',label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n',label_test.value_counts())\n",
        "  iris_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFxBRsT7tADh",
        "outputId": "5499f519-c5f9-434b-b4e9-3a15a609e067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차검증:1\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차검증:2\n",
            "학습 레이블 데이터 분포:\n",
            " 0    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차검증:3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ":Kfold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결해줌\n"
      ],
      "metadata": {
        "id": "nRjHkafKs_tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf=StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "\n",
        "for train_index,test_index in skf.split(iris_df,iris_df['label']):\n",
        "  n_iter+=1\n",
        "  label_train=iris_df['label'].iloc[train_index]\n",
        "  label_test=iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증:{0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n',label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n',label_test.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHHag53gy37n",
        "outputId": "6beeca2f-dead-4e60-b898-010a3c191338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증:1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "0    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    17\n",
            "1    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증:2\n",
            "학습 레이블 데이터 분포:\n",
            " 1    34\n",
            "0    33\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    17\n",
            "2    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증:3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "1    33\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    17\n",
            "2    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#붓꽃\n",
        "\n",
        "skfold=StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "#StratifiedKFold의 split() 호출 시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
        "for train_index,test_index in skfold.split(features,label):\n",
        "  #split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test=features[train_index],features[test_index]\n",
        "  y_train,y_test=label[train_index],label[test_index]\n",
        "\n",
        "\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train,y_train)\n",
        "  pred=dt_clf.predict(X_test)\n",
        "\n",
        "  #반복 시마다 정확도 측정\n",
        "  n_iter+=1\n",
        "  accuracy=np.round(accuracy_score(y_test,pred),4)\n",
        "  train_size=X_train.shape[0]\n",
        "  test_size=X_test.shape[0]\n",
        "  print('\\n{0} 교차 검증 정확도:{1}, 학습 데이터 크기:{2}, 검증 데이터 크기:{3}'.format(n_iter,accuracy,train_size,test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "#교차 검증별 정확도 및 평균 정확도 계산\n",
        "print('\\n## 교차 검증도 정확도:',np.round(cv_accuracy,4))\n",
        "print('## 평균 검증 정확도:',np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaEHbGi8z-81",
        "outputId": "0410d99b-1957-4036-c401-1bb17342848d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 교차 검증 정확도:0.98, 학습 데이터 크기:100, 검증 데이터 크기:50\n",
            "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "2 교차 검증 정확도:0.94, 학습 데이터 크기:100, 검증 데이터 크기:50\n",
            "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "3 교차 검증 정확도:0.98, 학습 데이터 크기:100, 검증 데이터 크기:50\n",
            "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 교차 검증도 정확도: [0.98 0.94 0.98]\n",
            "## 평균 검증 정확도: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###cross_val_score():교차검증 더 간편하게 할 수 있는 사이킷런의 API\n",
        "\n",
        "KFold로 데이터 학습하고 예측하는 코드\n",
        "1. 폴드 세트 설정\n",
        "2. for루프에서 반복으로 학습 및 테스트 데이터의 인덱스를 추출\n",
        "3. 반복적으로 학습과 예측 수행하고 예측 성능을 반환\n",
        "\n",
        "=>cross_val_score()은 한번에 수행\n",
        "\n",
        "\n",
        "```\n",
        "cross_val_score(estimator,X,y=None,scoring=None,n_jobs=1,verbose=1,fit_params=None,pre_dispatch='2*n_jobs')\n",
        "```\n",
        "\n",
        "* estimator:사이킷런의 분류 알고리즘 클래스인 Classifier 또는 회귀 알고리즘 클래스인 Regressor\n",
        "* X:피처 데이터 세트\n",
        "* y:레이블 데이터 세트\n",
        "* scoring: 예측 성능 평가 지표\n",
        "* cv: 교차 검증 폴드 수\n",
        "  * 수행 후 반환 값 scoring 파라미터로 지정된 성능 지표 측정값을 배열형태로 반환\n",
        "  * classifier 입력되면 Stratified K 폴드 방식으로 레이블값의 분포에 따라 학습/테스트 세트를 분할(회귀 시는 K 폴드 방식)\n",
        "\n",
        ":cv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가 지표로 평가 결과값을 배열로 반환\n",
        "일반적으로 이를 평균해 평균 수치로 사용\n",
        "\n",
        "* API 내부에서 fit(학습) predict(예측) 평가(evaluation)시켜주어 간단하게 교차 검증 수행할 수 있다\n",
        "\n",
        "붓꽃 데이터의 cross_val_score() 수행결과와 앞 예제의 붓꽃 데이터 StratifiedKFold의 수행결과를 비교해보면 각 교차 검증별 정확도와 평균 검증 정확도가 모두 동일\n",
        "\n",
        "*cross_val_score(): 여러 개의 평가 지표 반환 가능\n",
        "학습 데이터에 대한 성능 평가 지표와 수행 시간도 같이 제공"
      ],
      "metadata": {
        "id": "sTxbnpgp4Qum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "\n",
        "\n",
        "data=iris_data.data\n",
        "label=iris_data.target\n",
        "\n",
        "#성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
        "scores=cross_val_score(dt_clf,data,label,scoring='accuracy',cv=3)\n",
        "print('교차 검증별 정확도:',np.round(scores,4))\n",
        "print('평균 검증 정확도:',np.round(np.mean(scores),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhGiO1T04Pbi",
        "outputId": "16680050-b898-4ce2-feb1-4e2d1a299114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "평균 검증 정확도: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GridSearchCV:교차검증과 최적 하이퍼 파라미터 튜닝 한 번에\n",
        "\n",
        "* 하이퍼 파라미터: 머신러닝 알고리즘 구성 주요 요소-> 값을 조정해 알고리즘의 예측 성능 개선할 수 있다\n",
        "\n",
        "* GridSearchCV:교차 검증을 기반으로 이 하이퍼 파라미터의 최적 값 찾게 해줌\n",
        "\n",
        "* 데이터 세트를 cross-validation을 위한 학습/테스트 세트로 자동으로 분할한 뒤에 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해 최적의 파라미터를 찾을 수 있게함\n",
        "\n",
        "* 최적의 파라미터를 순차적으로 편리하게 찾게 해주지만, 시간이 오래걸림\n",
        "  * estimator:classifier, pipeline이 사용될 수 있다\n",
        "  * param_grid:key+리스트 값을 가지는 딕셔너리가 주어진다. estimator의 튜닝을 위해 파라미터명과 사용될 여러 파라미터값을 지정한다.\n",
        "  * scoring: 예측 성능을 측정할 평가방법 지정. 보통은 사이킷런의 성능 평가 지표를 지정하는 문자열(ex)정확도-accuracy)로 지정하나 별도의 성능 평가 지표 함수도 지정할 수 있다\n",
        "  * cv: 교차검증을 위해 분할되는 학습/테스트의 개수를 지정\n",
        "  * refit: 디폴트가 True 이며 True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킴"
      ],
      "metadata": {
        "id": "p7mBdaFj7bYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#결정 트리 알고리즘의 여러 하이퍼 파라미터를 순차적으로 변경하면서 최고 성능을 가지는 파라미터 조합 찾기\n",
        "#파라미터의 집합 만들고 순차적으로 적용해 최적화 수행\n",
        "\n",
        "grid_parameters={'max_depth':[1,2,3],'min_samples_split':[2,3]}"
      ],
      "metadata": {
        "id": "_2VRii_p8skM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "#데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
        "\n",
        "iris=load_iris()\n",
        "X_train,X_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=121)\n",
        "\n",
        "dtree=DecisionTreeClassifier()\n",
        "\n",
        "#파라미터를 딕셔너리 형태로 설정\n",
        "\n",
        "parameters={'max_depth':[1,2,3],'min_samples_split':[2,3]}\n"
      ],
      "metadata": {
        "id": "zHB8erHuBIWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#param_grid의 하이퍼 파라미터를 3개의 train,test set fold로 나누어 테스트 수행 설정\n",
        "#refit=True가 default. True면 가장 좋은 파라미터 설정으로 재학습\n",
        "grid_dtree=GridSearchCV(dtree,param_grid=parameters,cv=3,refit=True)\n",
        "\n",
        "#붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습,평가\n",
        "grid_dtree.fit(X_train,y_train)\n",
        "\n",
        "#GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "jD8-IH64B4-t",
        "outputId": "7bbdf3de-3e02-456f-8a90-ab3dbf64aced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     params  mean_test_score  rank_test_score  \\\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
              "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
              "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
              "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
              "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
              "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
              "\n",
              "   split0_test_score  split1_test_score  split2_test_score  \n",
              "0              0.700                0.7               0.70  \n",
              "1              0.700                0.7               0.70  \n",
              "2              0.925                1.0               0.95  \n",
              "3              0.925                1.0               0.95  \n",
              "4              0.975                1.0               0.95  \n",
              "5              0.975                1.0               0.95  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a7bc4e3-14b3-4be0-a042-dc02437376de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a7bc4e3-14b3-4be0-a042-dc02437376de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a7bc4e3-14b3-4be0-a042-dc02437376de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a7bc4e3-14b3-4be0-a042-dc02437376de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>max_depth와 min_samples_split을 순차적으로 총 6번 변경해 학습 및 평가 수행\n",
        "* params칼럼에는 수행할 때마다 적용된 하이퍼 파라미터값\n",
        "* rank_test_score: 하이퍼 파라미별로 성능이 좋은 score 순위. 1이 가장 뛰어난 순위 이때의 파라미터가 최적의 하이퍼 파라미터\n",
        "* mean_test_score: 개별 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값\n",
        "* best_params_: 최고 성능 하이퍼 파라미터 값 결과\n",
        "\n",
        "* best_score_ : 최고 성능 하이퍼 파라미터 평가 결과값"
      ],
      "metadata": {
        "id": "6AQdSMyL8sEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('GridSearchCV 최적 파라미터:',grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTVsBIatEu5w",
        "outputId": "1d308e6a-bb36-4cca-fe99-470669d9d029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도:0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GridSsearchCV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator=grid_dtree.best_estimator_\n",
        "\n",
        "#GridSearchCV의 best_estimator_은 이미 최적 학습이 됐으므로 별도 학습이 필요없음\n",
        "pred=estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도:{0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJgoqT5VFEXM",
        "outputId": "ff950f20-dba4-4575-b509-0df2ab089afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 세트 정확도:0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 학습 데이터를 GridSearchCV를 이용해 최적 하이퍼 파라미터 튜닝을 수행한 뒤에 별도의 테스트 세트에서 이를 평가하는 것이 일반적인 머신러닝 모델 적용 방법\n",
        "\n",
        "####데이터 전처리\n",
        ":ML 알고리즘은 데이터에 기반하고 있기 때문에 어떤 데이터를 입력으로 가지느냐에 따라 결과도 크게 달라질 수 있다\n",
        "\n",
        "* 결손값(NaN,NULL) 허용되지 않음-> 고정된 다른 값으로 변환해야함\n",
        "  * NULL 값 얼마 되지 않으면 피처의 평균값으로 간단히 대체 가능\n",
        "  * NULL 값 대부분이면 해당 피처 드롭하는 게 좋음\n",
        "* 사이킷런 머신러닝 알고리즘은 문자열 값을 입력값으로 허용되지 않음->숫자형 변환 필요\n",
        "  * 문자형: 카테고리형 피처, 텍스트형 피처\n",
        "    * 텍스트형: 피처 벡터화, 불필요하단 판단 시 삭제 \n",
        "\n",
        "### 데이터 인코딩\n",
        "\n",
        "#### 레이블 인코딩(label-encoding)\n",
        ":카테고리 피처를 코드형 숫자로 변환\n",
        "\n",
        " <font color='blue'> 01,02도 문자형이므로 1,2 와 같은 숫자형으로 구분해야함\n",
        "\n",
        "\n",
        " =>사이킷런: LabelEndcoder로 객체 생성 후 fit() transform()을 호출 해 레이블 인코딩 수행\n",
        "\n",
        "* 일괄적인 숫자값으로 변환되다 보니 몇몇 ML 알고리즘에서 이를 적용 시 예측 성능이 떨어짐-> 숫자 값의 경우 크고 작음에 대한 특성 발생하기 때문\n",
        "but, 큰 값 아니고 단순 특성, 중요도나 가중치 부여x\n",
        "\n",
        "=>판다스:get_dummies()"
      ],
      "metadata": {
        "id": "fZCfmgwUEul-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "#LabelEncoder을 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행\n",
        "encoder=LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels=encoder.transform(items)\n",
        "print('인코딩 변환값:',labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtd07WyE9X4z",
        "outputId": "19307a10-55bf-4f1c-b3f6-6340c5e6ec92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 많을 때 직관적으로 인코딩확인\n",
        "print('인코딩 클래스:',encoder.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpRdceNc-M8r",
        "outputId": "8b81260b-e076-49dc-ca9b-41f63d388f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인코딩된 값 다시 디코딩\n",
        "print('디코딩 원본값:',encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWQzJUVE-WVS",
        "outputId": "f1f09bc8-832a-4b85-8eef-489d70108052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####원-핫 인코딩(One-Hot encoding)\n",
        ":피처 값의 유형에 따라 새로운 피처를 추가해 고유값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식\n",
        "\n",
        "* 행 형태로 돼 있는 피처의 고유값을 열 형태로 차원을 변환한 뒤, 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0 표시\n",
        "\n",
        "=>사이킷런에서 OneHotEncoder 클래스로 쉽게 변환 가능\n",
        "* 주의점\n",
        " * OneHotEncoder로 변환하기 전 모든 문자열 값이 숫자형 값으로 변환되어야 함\n",
        " * 입력 값으로 2차원 데이터가 필요\n",
        " "
      ],
      "metadata": {
        "id": "Xmg0PfD5_FVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "#먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환\n",
        "encoder=LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels=encoder.transform(items)\n",
        "\n",
        "#2차원 데이터로 변환\n",
        "labels=labels.reshape(-1,1)\n",
        "\n",
        "#원-핫 인코딩 적용\n",
        "oh_encoder=OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels=oh_encoder.transform(labels)\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOtqdukj_yGl",
        "outputId": "78b6b852-2496-4757-8225-69d7776617a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원-핫 인코딩 데이터\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "원-핫 인코딩 데이터 차원\n",
            "(8, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#판다스 이용\n",
        "import pandas as pd\n",
        "df=pd.DataFrame({'item':['TV','냉장고','컴퓨터','선풍기','선풍기','믹서','믹서']})\n",
        "pd.get_dummies(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "3gCfzHN0BsUY",
        "outputId": "ffc5f3a5-127f-4347-b8ba-091df2c7aa2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item_TV  item_냉장고  item_믹서  item_선풍기  item_컴퓨터\n",
              "0        1         0        0         0         0\n",
              "1        0         1        0         0         0\n",
              "2        0         0        0         0         1\n",
              "3        0         0        0         1         0\n",
              "4        0         0        0         1         0\n",
              "5        0         0        1         0         0\n",
              "6        0         0        1         0         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dee3b559-d390-4e3f-9fbe-ca3e17781d5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_TV</th>\n",
              "      <th>item_냉장고</th>\n",
              "      <th>item_믹서</th>\n",
              "      <th>item_선풍기</th>\n",
              "      <th>item_컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dee3b559-d390-4e3f-9fbe-ca3e17781d5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dee3b559-d390-4e3f-9fbe-ca3e17781d5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dee3b559-d390-4e3f-9fbe-ca3e17781d5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###피처 스케일링과 정규화\n",
        "* 피처 스케일링: 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        " * 표준화: 데이터의 피처 각각이 평균이 0, 분산이 1인 가우시안 정규 분포를 가진 값으로 변환\n",
        " xi_new=(xi-mean(x))/stdev(x)\n",
        " * 정규화: 서로 다른 처의 크기를 통일하기 위해 크기를 변환해주는 개념.0~1의 값으로 변홤\n",
        "  * 개별 데이터의 크기를 모두 똑같은 단위로 변경\n",
        "xi_new=(xi-min(x))/(max(x)-min(x))\n",
        "\n",
        "* 사이킷런의 Normalizer 모듈과의 차이: 사이킷런 Normalizer 모듈은 선형대수에서 정규화 개념이 적용됐으며, 개별 벡터의 크기를 맞추기 위해 변환하는 것을 의미\n",
        "\n",
        "=>개별 벡터를 모든 피처벡터의 크기로 나눠줌\n",
        "xi_new=xi/sqrt(xi^2+yi^2+zi^2)\n"
      ],
      "metadata": {
        "id": "SDzN6QMcCHcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 사이킷런의 StandardSclaer\n",
        ":개별 피처를 평균이 0이고 분산이 1인 값으로 변환\n",
        "\n",
        "사이킷런에서 구현한 RBF 커널을 이용하는 서포트 벡터머신이나 선형 회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됐기 때문에 사전에 표준화를 적용하는 것은 예측 성능 향상에 중요 요소"
      ],
      "metadata": {
        "id": "vRw2h7OND9f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "#붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환\n",
        "iris=load_iris()\n",
        "iris_data=iris.data\n",
        "iris_df=pd.DataFrame(data=iris_data,columns=iris.feature_names)\n",
        "\n",
        "\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzvtWRZvD9BX",
        "outputId": "ce1e0a5e-bef3-444a-c622-89dbebcee5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#StandardScaler의 객체 생성\n",
        "scaler=StandardScaler()\n",
        "#StandardScaler로 데이터 세트 변환. fit()과 transform() 호출\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled=scaler.transform(iris_df)\n",
        "\n",
        "#transform()시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 반환\n",
        "iris_df_scaled=pd.DataFrame(data=iris_scaled,columns=iris.feature_names)\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df_scaled.var())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBDwDc1JFDrf",
        "outputId": "5f92adcb-56bb-4325-c9ab-ad77a57bed64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)   -1.690315e-15\n",
            "sepal width (cm)    -1.842970e-15\n",
            "petal length (cm)   -1.698641e-15\n",
            "petal width (cm)    -1.409243e-15\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    1.006711\n",
            "sepal width (cm)     1.006711\n",
            "petal length (cm)    1.006711\n",
            "petal width (cm)     1.006711\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "->모든 칼럼 값의 평균이 0에 아주 가까운 값으로, 분산은 1에 아주 가까운 값으로 변환됨\n",
        "\n",
        "\n",
        "* MinMaxScaler: 데이터값으로 0과 1사이의 범위 값으로 변환(음수 있으면 -1과 1사이로 변환)\n",
        " * 데이터의 분포가 가우시안 분포가 아닐 경우에 Min,Max Scaler을 적용해 볼 수 있다"
      ],
      "metadata": {
        "id": "CFmZs0GSGccC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#MinMaxScaler 객체 생성\n",
        "scaler=MinMaxScaler()\n",
        "#MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled=scaler.transform(iris_df)\n",
        "\n",
        "#transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled=pd.DataFrame(data=iris_scaled,columns=iris.feature_names)\n",
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRG8XlmJGbYM",
        "outputId": "aac43f85-fd9f-40aa-8bfc-1abfc19a0166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature들의 최솟값\n",
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "\n",
            "feature들의 최댓값\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
        ":StandardScaler이나 MixMaxScaler와 같은 Scaler 객체를 이용해 데이터의 스케일링 변환 시, \n",
        "  * fit()은 데이터 변환을 위한 기준 정보 설정을 적용(최솟값,최댓값)\n",
        "  * transform()은 fit에서 설정된 정보를 이용해 데이터를 변환\n",
        "  * fit_transform()은 fit()과 transform() 한번에 적용"
      ],
      "metadata": {
        "id": "8CW4VDYVH9Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "#학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n",
        "#scaler 클래스의 fit() transform()은 2차원 이상 데이터만 가능하므로 reshape(-1,1)로 차원 변경\n",
        "train_array=np.arange(0,11).reshape(-1,1)\n",
        "test_array=np.arange(0,6).reshape(-1,1)\n"
      ],
      "metadata": {
        "id": "o10HRlOlGZB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data.MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0-1 값으로 변환\n",
        "scaler=MinMaxScaler()\n",
        "\n",
        "#fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정\n",
        "scaler.fit(train_array)\n",
        "\n",
        "#1/10 scale로 train_array 데이터 변환함. 원본 10->1로 변환됨\n",
        "train_scaled=scaler.transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터:',np.round(train_array.reshape(-1),2))\n",
        "print('scale된 train_array 데이터:',np.round(train_scaled.reshape(-1),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsnr6nMbLtB0",
        "outputId": "26b3f6c5-eb6a-4733-9116-eed50ac06e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_data.MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정\n",
        "scaler.fit(test_array)\n",
        "\n",
        "#1/5 scale로 test_array 데이터 변환. 원본 5->1로 변환\n",
        "test_scaled=scaler.transform(test_array)\n",
        "\n",
        "#test_array의 scale 변환 출력\n",
        "print('원본 test_array 데이터:',np.round(test_array.reshape(-1),2))\n",
        "print('Scale된 test_array 데이터:',np.round(test_scaled.reshape(-1),2))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9_PVEzpMnV0",
        "outputId": "b714f4e9-9f12-4678-fa88-eb239577b250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "->서로 다른 원본값이 동일한 값으로 변환되는 결과를 초래\n",
        "\n",
        "머신러닝 모델은 학습데이터를 기반으로 학습되기 때문에 반드시 테스트 데이터는 학습 데이터의 스케일링 기준에 따라야 하며, 테스트 데이터의 1값은 학습 데이터와 동일하게 0,1 값으로 변환돼야 함\n",
        "\n",
        "->이미 fit이 적용된 scaler 객체를 이용해 테스트 데이터를 transform()으로 변환\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7UlsdVNMNgwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import transform\n",
        "scaler=MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled=scaler.transform(train_array)\n",
        "print('원본 train_array 데이터:',np.round(train_array.reshape(-1),2))\n",
        "print('scale된 train_array 데이터:',np.round(train_scaled.reshape(-1),2))\n",
        "\n",
        "#test_array에 scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform()만으로 변환해야 함\n",
        "test_scaled=scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터:',np.round(test_array.reshape(-1),2))\n",
        "print('Scale된 test_array 데이터:',np.round(test_scaled.reshape(-1),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rKl3yZbNPti",
        "outputId": "ba6baca8-1aa9-4461-f18f-8768e2ca968e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "\n",
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* 가능하다면 전체 데이터의 스케일링 변환을 적용한뒤 학습과 테스트 데이터로 분리\n",
        "* 안된다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 scaler 객체를 이용해  transform() 으로 변환//\n",
        "여기까지 과제 범위\n",
        "\n"
      ],
      "metadata": {
        "id": "Uboe65MKQN1x"
      }
    }
  ]
}